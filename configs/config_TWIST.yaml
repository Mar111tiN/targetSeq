inputdirs: 
  - /fast/users/szyskam_c/work/downloads/NGSData/Twist1 # source of fastq files (subfolders allowed)
workdir: /fast/users/szyskam_c/scratch/projects/Twist1 # here your results are created
snakedir: /fast/users/szyskam_c/snakes/develop/targetSeq
samples: # here go all your samples
  samplesheet: /fast/users/szyskam_c/snakes/develop/targetSeq/sheets/testrun1.csv
  reads:
    - R1
    - R2
  umi_barcode: index # suffix for the fastq containing the umi-barcode
setup:
  cleanup:
    run: True
    keep_only_final_bam: True
  run: PE   # SE run is not implemented
  phred: 33
  library: SureSelect  # have to be found at bed_files/SureSelect/<build>/SS_<library_version>_<build>_<Padded | Covered>[_nochr].bed
  library_version: HAEv7
  platform: illumina
  Flowcell: HKCN3DRXX
  Instrument: A00643
  platform_unit: A00643.HKCN3DRXX
  UMI: False  # if UMI information should be used in pipeline
  # if UMI_filter is true: deduplication is substituted with the UMI-filter pipeline
  # else: umi-aware deduplication is used 

#### ABSOLUTE PATHS ############
paths:
  mystatic: /fast/groups/ag_damm/work/ref/
  bihstatic: /fast/projects/cubit/current/static_data
  scripts: scripts/ # folder relative to snakedir
  filter_settings: /fast/users/szyskam_c/snakes/develop/somVarWES/info
#### REF SECTION ###############
ref:
  build: hg38
  hg19:
    genome_path: genome/gatk/b37
    genome: genome/gatk/b37/human_g1k_v37.fasta
    genome_split: genome/gatk/b37/split
    candidates: /fast/users/szyskam_c/work/utils/bulltools/known_sites/candidate_genes_aml.txt
    dbsnp: annotation/gatk/b37/dbsnp_138.b37.vcf
    dbsnp_all: annotation/gatk/b37/All_20180423.vcf
    dbsnp_common: annotation/gatk/b37/common_all_20180423.vcf
    gold_standard_indels: annotation/gatk/b37/Mills_and_1000G_gold_standard.indels.b37.vcf
    phase1k_indels: annotation/gatk/b37/1000G_phase1.indels.b37.vcf
    # bed_file: bed_files/SureSelect/hg19/SS_HAEv6r2_hg19_Covered_nochr.bed
    # bed_file_pad: bed_files/SureSelect/hg19/SS_HAEv6r2_hg19_Padded_nochr.bed
  hg38:
    genome_path: genome/gatk/hg38/
    genome: genome/gatk/hg38/hg38.fasta
    genome_split: genome/gatk/hg38/split
    dbsnp: annotation/gatk/hg38/dbsnp_138.hg38.vcf
    dbsnp_all: annotation/gatk/hg38/All_20180418.vcf
    dbsnp_common: annotation/gatk/hg38/common_all_20180418.vcf
    gold_standard_indels: annotation/gatk/hg38/Mills_and_1000G_gold_standard.indels.hg38.vcf
    phase1k_indels: annotation/gatk/hg38/1000G_phase1.snps.high_confidence.hg38.vcf # seems to work instead of indels (acc. to GATK blog: https://gatkforums.broadinstitute.org/gatk/discussion/6800/known-sites-for-indel-realignment-and-bqsr-in-hg38-bundle)
    bed_file: bed_files/Twist/hg38/DKMS_v5_hg38.bed
    # bed_file_pad: bed_files/SureSelect/hg38/SS_HAEv7_hg38_Padded.bed
#### TOOLS SECTION ##############
tools:
  gatk: gatk # 
  gatk3: java -jar /fast/users/szyskam_c/work/utils/gatk3.8/GenomeAnalysisTK.jar -T
  # annovar: perl /fast/users/szyskam_c/tools/annovar2018
  annovar: perl /fast/users/szyskam_c/tools/annovar2019
scripts:
  split_fastq: shell/split_fastq.mawk
  prettifyBED : shell/prettify_BEDcoverage.awk
  anno_format: shell/anno_format.mawk
  vcf2table: shell/vcf2table.mawk
  cleanpileup: shell/cleanpileup.mawk
  varscan2table: shell/varscan2table.mawk
  anno_info: shell/anno_info.mawk
  csv2bed: shell/csv2bed.mawk
  pon2cols: shell/pon2cols.mawk
  format_bed_coverage: shell/formatCoverage.sh
  cleanpileup: shell/cleanpileup.mawk
  pile2count: shell/pile2count.mawk
  matrix2EBinput: shell/matrix2EBinput.mawk
  makeponlist: shell/makeponlist.sh
  reducematrix: shell/matrix_minus_sample.mawk
  reordermatrix: shell/reorder_matrix.mawk
  # merge_anno: merge_anno.py
  # expand_info: shell/expand_info.sh
  
  # filter_csv: shell/filter_exome_wFlankingSeq.sh
fastq:
  threads: 20
  split_factor: 20 # split fastqs and run pipeline on split files --> merge before deduplication
qc:
  samplefactor: 1
trim: # trimming induces misaligned fastqs (index fastq)
  run: False # should only be used if UMI is not used
  program: trimmomatic
  threads: 24
  adapters: info/SureSelectXT.fa
  mode: 
    - "AVGQUAL:20"
    # - "SLIDINGWINDOW:4:15"
    # - "LEADING:3"
    # - "ILLUMINACLIP:<adapter>:2:30:10"
  suffix:
    - "trim"  # suffix for paired output
    - "trim_UP" # suffix for unpaired output
ubamXT:
    threads: 8
    use_jdk: True # use_jdk_in/deflater to avoid SIGSEV error
alignment:
  tool: bwa
  threads: 16
  clip_overlap: False
  strategy: MostDistant  # alignment strategy for MergeBamAlignment
  use_jdk: True
bamindex:
  threads: 2
tag_bam: # needs enough RAM for loading entire uncompressed index fastq into memory
  run: True
  max_mem: 30g # memory for java VM (30g seems neccessary - needs to be smaller than threads * vmem/thread)
resplit_bam:
  threads: 20
dedup:
  threads: 4
dedup_umi:
  max_mem: 10g
  keep_dups: True # keep dups if you want to perform UMI-correction
realignGATK:
  threads: 16
recalib:
  run: True
  threads: 12
  known_sites: dbsnp_common   # which dbsnp database to use beside gold_standard_indels and phase1k
UMI_filter:
  run: False # if False and setup-->UMI is True, run umi-dedup
  min_reads:  1 # for WES-data, 1 is good; for targeted >3  counts for all fgbio tools
  group:
    threads: 10
    mem: 2G
    group_strategy: adjacency
    min_base_Q: 20
    min_map_q: 20
    edits: 1  # 1 edit in a umi-node should be ok
  call:
    threads: 6
    mem: 6G
    error_rate_pre_umi: 45
    error_rate_post_umi: 40
    min_input_Q: 20 # input base quality (10 is default; IDT says 30)
  remap:
    threads: 10
    mem: 6G
    clip_overlap: True
    clip_adapters: True
  filter:
    threads: 6
    mem: 6G
    max_error_rate_per_read: 0.05
    max_error_rate_per_base: 0.1
    min_Q: 30 # input base quality
    max_no_call: 0.1 # fraction of reads filtered per M/e
cover_bed:
  histo_steps: "0 1 10 15 50 100 120 200 500 1000 1500 2000 2500"
bam_metrix:
  threads: 6
  bait: bed_files/Twist/hg38/DKMS_v5_hg38.bed # path relative to ref folder
  target: bed_files/Twist/hg38/DKMS_v5_hg38.bed # path relative to ref folder
mpileup:
  Q: 25   # base quality
  MAPQ: 20 # -q in pileup
freebayes:
  threads: 8
  use-bed-file: False
  min-alternate-count: 3
  min-alternate-fraction: 0.02
  q: 25 # base quality
  Q: 20 # mapping quality
annovar:
  threads: 10
  path_to_humandb: annotation/annovar/humandb
  annofiles:
    - refGene
    - cytoBand
    - genomicSuperDups
    # - esp6500_all
    - esp6500siv2_all  #
    # - 1000g2010nov_all
    - 1000g2014oct_all
    - gnomad_exome_all
    # - gnomad_af.lna # not indexed
    # - exac03_all
    # - dbscsnv11
    # - snp131
    # - snp131NonFlagged
    - snp138
    - snp138NonFlagged
    - avsnp138
    - avsnp150
    - cosmic70
    - cosmic90
    # - clinvar_20150629
    # - clinvar_20170905
    - clinvar2019_short
    # - ljb26_all
    # - dbnsfp30a
    - dbnsfp35a
    - spidex
    - icgc29
Fisher_strand:
  threads: 20
EBFilter:
  run: True
  pon_list: PoN/HAEv7_hg38_NovaSeq/Pon_list.txt # path relative to mystatic path
  use_cache: True
  cache_folder: PoN/HAEv7_hg38_NovaSeq # path relative to mystatic path
  full_pon_output: False
  threads:
    pileup: 12
    makeEBcache: 20
    EBscore: 20
    EBsplit_factor: 20 # into how many jobs is makeEBcache divided per chromosome
  params:
    sep: tab
    MAPQ: 20   # I guess this should be lower than the mapping quality used for mpileup or not?
    Q: 25
    fitting_penalty: 0.5
filter:
  threads: 2
  filter_settings: filter_AML.csv
  edit:
    extended_output: False
    candidate_list: annotation/damm_lists/AML_candidates.txt
    driver_list: annotation/damm_lists/AML_drivers.txt
  filter_name: damm
  run: True
  filter1: damm1.py
  filter2: damm2.py
  keep_syn: False
filter_bam:
    threads: 4
    stringency_for_bam: loose # from which filter2 should the filter bam be generated
    stringency_for_IGVnav: moderate
    padding: 200
    folder: filterbam
primer3:  # is applied after filter step 1
  threads: 10
  min_size: 120
  max_size: 220
  center_offSet: 5 # how much offSet primer pairs can
  use_primer_list: ''
HDR:
  min_similarity: .85 # which similarities to consider as HDR
  padding: 150  # range around mutation to be scanned