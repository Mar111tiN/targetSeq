# ################# FILTER ###################################################
rule filter1:
    input: "filter/{sample}_{tumor}-{normal}.csv"
    output: 
        filter1 = "table/{sample}_{tumor}-{normal}.filter1.csv",
        basic = "filter/{sample}_{tumor}-{normal}.basic.csv"
    wildcard_constraints:
        sample = "[^_]+"
    threads:
        config['filter']['threads']
    script:
        "../scripts/filters/damm1.py" 


rule primer3:
    input: "table/{sample}_{tumor}-{normal}.filter1.csv"
    output: "table/{sample}_{tumor}-{normal}.filter1.primer.csv"
    conda:
        "../env/primer3-env.yml"
    threads:
        config['primer3']['threads']
    params:
        genome_split = full_path('genome_split')
    script:
        "../scripts/primer3.py"


rule detect_HDR:
    input:
        filter_file = "table/{sample}_{tumor}-{normal}.filter1.csv",
        filter_bam = "bam_done/{sample}_{tumor}-{normal}.filter1.done",
        pileup = "pileup/{sample}_{tumor}-{normal}.filter1.pileup"
    output:
        HDR = "table/{sample}_{tumor}-{normal}.filter1.HDR.csv"
    conda:
        "../env/HDR-env.yml"
    threads:
        2
    params:
        min_sim = config['HDR']['min_similarity']
    script:
        "../scripts/HDR.py"


rule filter_bam:
    input:
        csv = "table/{sample}_{tumor}-{normal}.{filter}.csv",
        tumor_bam = "recalib/{sample}_{tumor}.bam",
        tumor_bai = "recalib/{sample}_{tumor}.bai",
        normal_bam = "recalib/{sample}_{normal}.bam",
        normal_bai = "recalib/{sample}_{normal}.bai",
    output:
        # tumor_bam = "filterbam/{sample}_{tumor}.{filter}.bam",
        # tumor_bai = "filterbam/{sample}_{tumor}.{filter}.bai",
        # normal_bam = "filterbam/{sample}_{normal}.{filter}.bam",
        # normal_bai = "filterbam/{sample}_{normal}.{filter}.bai",
        done = "bam_done/{sample}_{tumor}-{normal}.{filter}.done"
    conda:
        "../env/align-env.yml"
    threads:
        config['filter_bam']['threads']
    params:
        folder = config['filter_bam']['folder'],
        mut_bed_file = get_mut_bed,
        tumor_bam = lambda w, input: input.tumor_bam.replace(os.path.split(input.tumor_bam)[0], config['filter_bam']['folder']).replace(".bam", f".{w.filter}.bam"),
        normal_bam = lambda w, input: input.normal_bam.replace(os.path.split(input.normal_bam)[0], config['filter_bam']['folder']).replace(".bam", f".{w.filter}.bam")
    shell:
        "mkdir -p {params.folder}; "
        "samtools view -bhL {params.mut_bed_file} {input.tumor_bam} > {params.tumor_bam}; "
        "picard BuildBamIndex INPUT={params.tumor_bam}; "
        "samtools view -bhL {params.mut_bed_file} {input.normal_bam} > {params.normal_bam}; "
        "picard BuildBamIndex INPUT={params.normal_bam}; "
        "rm -f {params.mut_bed_file}; "
        "touch {output.done}"

rule filter_pileup:
    input:
        bam = "bam_done/{sample}_{tumor}-{normal}.filter1.done"
    output:
        pileup = "pileup/{sample}_{tumor}-{normal}.filter1.pileup"
    threads:
        2
    conda:
        "../env/align-env.yml"
    params:
        input = lambda w: f"{config['filter_bam']['folder']}/{w.sample}_{w.tumor}.filter1.bam {config['filter_bam']['folder']}/{w.sample}_{w.normal}.filter1.bam",
        refgen = full_path('genome'),
        qual = f"-q {config['mpileup']['MAPQ']} -Q {config['mpileup']['Q']}",
        cleanpileup = get_script('cleanpileup')
    shell:
        "samtools mpileup -f {params.refgen} {params.qual} {params.input} | {params.cleanpileup} > {output.pileup}"

rule combine_filter1:
    input:
        filter1 = "table/{sample}_{tumor}-{normal}.filter1.csv",
        primer = "table/{sample}_{tumor}-{normal}.filter1.primer.csv",
        HDR = "table/{sample}_{tumor}-{normal}.filter1.HDR.csv"
    output: "filter/{sample}_{tumor}-{normal}.filter1.csv"
    threads: 2
    run:
        ## merge the files
        print(f'Merging {input.primer} and {input.HDR} into {input.filter1}..')
        filter1_df = pd.read_csv(input.filter1, sep='\t')
        HDR_df = pd.read_csv(input.HDR, sep='\t')
        primer_df = pd.read_csv(input.primer, sep='\t')
        merge = pd.merge(filter1_df, HDR_df, how='inner', on=['Chr', 'Start', 'End', 'Ref', 'Alt', 'Gene'])
        merge_df = pd.merge(merge, primer_df, how='inner', on=['Chr', 'Start', 'End', 'Ref', 'Alt', 'Gene'])

        output = str(output)
        print(f"Writing merged filter1-list to {output}.")
        merge_df.to_csv(output, sep='\t', index = False)

rule filter2:
    input: 
        filter1 = "filter/{sample}_{tumor}-{normal}.filter1.csv"
    output: 
        # filter2.loose is a placeholder for all the filter2 files:
        #  loose.csv
        #  moderate.csv
        #  strict.csv
        filter2 = "filter/{sample}_{tumor}-{normal}.filter2.loose.csv",
        filter2_for_filterbam = "table/{sample}_{tumor}-{normal}.filter2.csv"
    threads: 
        2
    conda:
        "../env/filter2-env.yml"
    script:
        "../scripts/filters/damm2.py"



rule IGVnav:
    input:
        filter = "filter/{sample}_{tumor}-{normal}.filter2.loose.csv",
        bam = "bam_done/{sample}_{tumor}-{normal}.filter2.done"
    output:
        filterbam = "filterbam/{sample}_{tumor}-{normal}.filter2.IGVnav.txt"
    threads:
        1
    run:
        # selectinng the right filter2 file from the configs
        filter_file = input.filter.replace(".loose.csv", f".{config['filter_bam']['stringency_for_IGVnav']}.csv")
        df = pd.read_csv(filter_file, sep='\t', index_col=False).iloc[:, :5]
        print(f'Loaded {filter_file}')
        for col in ['Call', 'Tags', 'Notes']:
            df[col] = ''
        df.loc[:, 'Chr'] = df['Chr'].str.replace('chr', '')
        df.to_csv(str(output), sep='\t', index=False)
        print(f"Written to {output.filterbam}")


